{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Azure OpenAI GPT-4 Vision to extract structured JSON data from Image documents\n",
    "\n",
    "This notebook demonstrates [how to use GPT-4 Vision](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/gpt-with-vision?tabs=rest) to extract structured JSON data from Image documents, using the [Azure OpenAI Service](https://learn.microsoft.com/en-us/azure/ai-services/openai/overview).\n",
    "\n",
    "This is Modified Code of this Repo, to see more detailed look, please visit [Using Azure OpenAI GPT-4 Vision to extract structured JSON data from PDF documents](https://learn.microsoft.com/en-us/samples/azure-samples/azure-openai-gpt-4-vision-pdf-extraction-sample/using-azure-openai-gpt-4-vision-to-extract-structured-json-data-from-pdf-documents/)\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "The notebook uses [.NET 8](https://dotnet.microsoft.com/download/dotnet/8.0) to run the C# code that interacts with the Azure OpenAI Service.\n",
    "\n",
    "### Other Requirements\n",
    "\n",
    "- Install the latest [**.NET SDK**](https://dotnet.microsoft.com/download).\n",
    "- Install [**Visual Studio Code**](https://code.visualstudio.com/) with the [**Polyglot Notebooks extension**](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode).\n",
    "\n",
    "\n",
    "**Note**: The GPT-4 Vision model is currently in preview and is available in limited capacity (10K per region) in selected regions only. For more information, see the [Azure OpenAI Service documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-preview-model-availability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install .NET dependencies\n",
    "\n",
    "This notebook uses .NET to interact with the Azure OpenAI Service. It takes advantage of the following NuGet packages:\n",
    "\n",
    "### DotNetEnv\n",
    "\n",
    "The [DotNetEnv](https://github.com/tonerdo/dotnet-env) library is used to load environment variables from a `.env` file which can be accessed via the `Environment.GetEnvironmentVariable(string)` method. This library is used to load the Azure OpenAI Service endpoint, key and model deployment name from the [`./config.env`](./config.env) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>DotNetEnv, 3.0.0</span></li><li><span>System.Text.Json, 8.0.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:System.Text.Json, 8.0.1\"\n",
    "#r \"nuget:DotNetEnv, 3.0.0\"\n",
    "\n",
    "using System.Net;\n",
    "using System.Net.Http;\n",
    "using System.Text.Json.Nodes;\n",
    "using System.Text.Json;\n",
    "using System.IO; \n",
    "\n",
    "using DotNetEnv;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "Env.Load(\"config.env\");\n",
    "\n",
    "var endpoint = Environment.GetEnvironmentVariable(\"AZURE_OPENAI_ENDPOINT\");\n",
    "var apiKey = Environment.GetEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n",
    "var modelDeployment = Environment.GetEnvironmentVariable(\"AZURE_OPENAI_VISION_MODEL_DEPLOYMENT_NAME\");\n",
    "var apiVersion = \"2023-12-01-preview\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GPT-4-Vision-Preview to extract the data from the image\n",
    "\n",
    "The GPT-4 Vision model can be used to extract structured JSON data from the image. The following code demonstrates how to use the deployed Azure OpenAI Service directly via the API to extract structured JSON data from the image.\n",
    "\n",
    "In this example, the payload for the Chat completion endpoint is a JSON object with the following details:\n",
    "\n",
    "### System Prompt\n",
    "\n",
    "The system prompt is the instruction to the model that prescribes the model's behavior. They allow you to constrain the model's behavior to a specific task, making it more adaptable for specific use cases, such as extracting structured JSON data from documents.\n",
    "\n",
    "In this case, it is to extract structured JSON data from the image. Here is what we have provided:\n",
    "\n",
    "**You are an AI assistant that extracts data from documents and returns them as structured JSON objects.**\n",
    "\n",
    "Learn more about [system prompts](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/system-message).\n",
    "\n",
    "### User Prompt\n",
    "\n",
    "The user prompt is the input to the model that provides context for the model's response. It is the input that the model uses to generate a response. \n",
    "\n",
    "In this case, it is the image of the document plus some additional text context to help the model understand the task. Here is what we have provided:\n",
    "\n",
    "**Extract the data from this invoice. Provide the Company Details, Invoice For, and Invoices**\n",
    "\n",
    "> **Note:** For the user prompt, we do not need to specify the response as JSON. This is because the system prompt already specifies that the response should be structured JSON data.\n",
    "\n",
    "This prompt ensures that the model understands the task, and the additional text context provides the model with the necessary information to extract the structured JSON data from the image. This approach would result in a response similar to the following:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"Company Details\": {\n",
    "    \"Name\": \"Contoso\",\n",
    "    \"Address\": \"1 Redmond way Suite 6000 Redmond, WA 99243\"\n",
    "  },\n",
    "  \"Invoice For\": {\n",
    "    \"Name\": \"Microsoft\",\n",
    "    \"Address\": \"1020 Enterprise Way Sunnyvale, CA 87659\"\n",
    "  },\n",
    "  \"Invoices\": [\n",
    "    {\n",
    "      \"Invoice Number\": \"34278587\",\n",
    "      \"Invoice Date\": \"6/18/2017\",\n",
    "      \"Invoice Due Date\": \"6/24/2017\",\n",
    "      \"Charges\": \"$56,651.49\",\n",
    "      \"VAT ID\": \"PT\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// REPLACE THE FILE NAME\n",
    "var imageFileName = \"HP Scan Document_3-3.jpg\";\n",
    "var base64Image = Convert.ToBase64String(File.ReadAllBytes(imageFileName));\n",
    "\n",
    "\n",
    "JsonObject jsonPayload = new JsonObject\n",
    "{\n",
    "    {\n",
    "        \"messages\", new JsonArray \n",
    "        {\n",
    "            new JsonObject\n",
    "            {\n",
    "                { \"role\", \"system\" },\n",
    "                { \"content\", \"You are an AI assistant that extracts data from documents and returns them as structured JSON\" }\n",
    "            },\n",
    "            new JsonObject\n",
    "            {\n",
    "                { \"role\", \"user\" },\n",
    "                { \"content\",\n",
    "                    new JsonArray\n",
    "                    {\n",
    "                        new JsonObject\n",
    "                        {\n",
    "                            { \"type\", \"text\" },\n",
    "                            { \"text\", \"Extract the data from this invoice. Provide the Borrower Name, CUSIP, Total Loan Amount, and Date.\" }\n",
    "                        },\n",
    "                        new JsonObject\n",
    "                        {\n",
    "                            { \"type\", \"image_url\" },\n",
    "                            { \"image_url\", new JsonObject { { \"url\", $\"data:image/jpeg;base64,{base64String}\" } } }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    { \"model\", modelDeployment },\n",
    "    { \"max_tokens\", 300 },\n",
    "    { \"temperature\", 0.1 },\n",
    "    { \"top_p\", 0.1 },\n",
    "};\n",
    "\n",
    "string payload = JsonSerializer.Serialize(jsonPayload, new JsonSerializerOptions\n",
    "{\n",
    "    WriteIndented = true\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: ```json\n",
      "{\n",
      "  \"Borrower Name\": \"GFL ENVIRONMENTAL INC\",\n",
      "  \"CUSIP\": \"C7052B4CT\",\n",
      "  \"Total Loan Amount\": \"USD 1,330,669,937.23\",\n",
      "  \"Date\": \"22nd MARCH 2021\"\n",
      "}\n",
      "```\r\n"
     ]
    }
   ],
   "source": [
    "string visionEndpoint = $\"{endpoint}openai/deployments/{modelDeployment}/chat/completions?api-version={apiVersion}\";\n",
    "\n",
    "using (HttpClient httpClient = new HttpClient())\n",
    "{\n",
    "    httpClient.BaseAddress = new Uri(visionEndpoint);\n",
    "    httpClient.DefaultRequestHeaders.Add(\"api-key\", apiKey);\n",
    "    httpClient.DefaultRequestHeaders.Accept.Add(new System.Net.Http.Headers.MediaTypeWithQualityHeaderValue(\"application/json\"));\n",
    "\n",
    "    var stringContent = new StringContent(payload, Encoding.UTF8, \"application/json\");\n",
    "\n",
    "    var response = await httpClient.PostAsync(visionEndpoint, stringContent);\n",
    "\n",
    "    if (response.IsSuccessStatusCode)\n",
    "    {\n",
    "        using (var responseStream = await response.Content.ReadAsStreamAsync())\n",
    "        {\n",
    "            // Parse the JSON response using JsonDocument\n",
    "            using (var jsonDoc = await JsonDocument.ParseAsync(responseStream))\n",
    "            {\n",
    "                // Access the message content dynamically\n",
    "                JsonElement jsonElement = jsonDoc.RootElement;\n",
    "                string messageContent = jsonElement.GetProperty(\"choices\")[0].GetProperty(\"message\").GetProperty(\"content\").GetString();\n",
    "\n",
    "                // Output the message content\n",
    "                Console.WriteLine($\"Output: {messageContent}\");\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        Console.WriteLine($\"Error: {response}\");\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
